
import random
import math
import pandas as pd
import numpy as np
from deap import base, creator, tools,algorithms
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# import pygad
# from tensorflow.python.keras.models import Sequential, load_model
# from tensorflow.python.keras.layers import LSTM, Dense

data = pd.read_excel('Proyecto de Grado\DataSetPruebas.xlsx')
seed = 1234
Train,Test = train_test_split(data, random_state=seed)
print(Train.shape)
print(Test.shape)


# # Creamos los objetos para definir el problema y el tipo de individuo
# creator.create("FitnessMax", base.Fitness, weights=(1.0,))
# creator.create("Individual", list, fitness=creator.FitnessMax)

# def funcion_objetivo(x):
#     for i in range(len(x)):
#         if x[i] > 100 or x[i] < -100:
#             return -1,
#     res = math.sqrt(x[0]**2 + x[1]**2)        
#     return res,
# toolbox = base.Toolbox()

# # Generación de genes 
# toolbox.register("attr_uniform", random.uniform, -100, 100)

# # Generación de inviduos y población
# toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_uniform, 2)
# toolbox.register("population", tools.initRepeat, list, toolbox.individual, 50)

# # Registro de operaciones genéticas
# toolbox.register("evaluate", funcion_objetivo)
# toolbox.register("mate", tools.cxOnePoint)
# toolbox.register("mutate", tools.mutGaussian, mu=0, sigma= 5, indpb=0.1)
# toolbox.register("select", tools.selTournament, tournsize=3)

# # def plot_evolucion(log):
# #     """
# #     Representa la evolución del mejor individuo en cada generación
# #     """
# #     gen = log.select("gen")
# #     fit_mins = log.select("min")
# #     fit_maxs = log.select("max")
# #     fit_ave = log.select("avg")

# #     fig, ax1 = plt.subplots()
# #     ax1.plot(gen, fit_mins, "b")
# #     ax1.plot(gen, fit_maxs, "r")
# #     ax1.plot(gen, fit_ave, "--k")
# #     ax1.fill_between(gen, fit_mins, fit_maxs, 
# #                      where=fit_maxs >= fit_mins, facecolor='g', alpha = 0.2)
# #     ax1.set_xlabel("Generation")
# #     ax1.set_ylabel("Fitness")
# #     ax1.set_ylim([-10, 160])
# #     ax1.legend(["Min", "Max", "Avg"], loc="lower center")
# #     plt.grid(True)
# #     plt.savefig("Convergencia.eps", dpi = 300)

# def main():
#     CXPB, MUTPB, NGEN = 0.5, 0.2, 20
#     pop = toolbox.population() 
#     hof = tools.HallOfFame(1) 
#     stats = tools.Statistics(lambda ind: ind.fitness.values) 
#     stats.register("avg", np.mean)
#     stats.register("std", np.std)
#     stats.register("min", np.min)
#     stats.register("max", np.max)
#     logbook = tools.Logbook()
#     pop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=CXPB, 
#                                        mutpb=MUTPB, ngen=NGEN, stats=stats, 
#                                        halloffame=hof, verbose=True)
#     return hof 


# if __name__ == "__main__":
#     random.seed(42)
#     lista_mejores = list()  
#     for i in range(20): 
#         best = main()
#         lista_mejores.append(best[0].fitness.values)
#     media = np.mean(lista_mejores)
#     mejor_total = max(lista_mejores)
#     print("media %f" % media)
#     print("mejor %f" % mejor_total)
